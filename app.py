import streamlit as st
import os
import pandas as pd
import numpy as np
from langchain.chat_models import init_chat_model
from langchain.schema import SystemMessage, HumanMessage, AIMessage
import PyPDF2
import time
import random
from datetime import datetime, timedelta
import requests
import tempfile
import edge_tts
import asyncio
import base64

try:
    from mutagen.mp3 import MP3
    mutagen_available = True
except ImportError:
    mutagen_available = False

def speak_text(text, voice="alpha"):
    voice_map = {
        "alpha": "en-US-JennyNeural",
        "beta": "en-GB-RyanNeural",
    }
    real_voice = voice_map.get(voice, "en-US-JennyNeural")

    async def run_tts():
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmpfile:
            communicate = edge_tts.Communicate(text, real_voice)
            await communicate.save(tmpfile.name)

            with open(tmpfile.name, "rb") as audio_file:
                audio_bytes = audio_file.read()
                b64_audio = base64.b64encode(audio_bytes).decode()

            st.markdown(f"""
                <audio autoplay>
                    <source src="data:audio/mp3;base64,{b64_audio}" type="audio/mp3">
                </audio>
            """, unsafe_allow_html=True)

            duration = get_mp3_duration(tmpfile.name, text)
            time.sleep(duration)

    asyncio.run(run_tts())

def get_mp3_duration(file_path, text):
    if mutagen_available:
        audio = MP3(file_path)
        return audio.info.length
    else:
        words = len(text.split())
        return max(words / 2.5, 2)

def get_user_ip_ad():
    try:
        response = requests.get('https://api.ipify.org?format=json', timeout=2)
        return response.json().get("ip", "")
    except Exception:
        return ""

def is_csusb(ip):
    return any([
        ip.startswith("138.23."),
        ip.startswith("139.182.")
    ])

def generate_alpha_question_intro(q_num, question):
    if q_num == 0:
        starters = [
            "Alright Beta, let's kick things off‚Äî",
            "Okay, first up‚Äî",
            "Let's dive into it‚Äî",
            "To get us started‚Äî",
            "Kicking things off, Beta‚Äî"
        ]
    else:
        starters = [
            f"Question {q_num + 1} coming at you‚Äî",
            "Alright, next up‚Äî",
            "Let's keep it rolling‚Äî",
            "Here's another one‚Äî",
            "This one's interesting‚Äî"
        ]
    return random.choice(starters) + question

st.set_page_config(
    page_title="CSUSB Study Podcast",
    page_icon="logo/csusb_logo.png",
)

st.markdown("""
<style>
div[data-testid="stFileUploader"] div[aria-live="polite"] {
    display: none !important;
}
.stButton button { width: 100%; }
.submit-button-container {
    display: flex;
    align-items: flex-end;
    padding-bottom: 0 !important;
    margin-bottom: 0 !important;
}
.stTextInput > div > div > input {
    padding-bottom: 0 !important;
}
</style>
""", unsafe_allow_html=True)

col1, col2, col3 = st.columns([1, 3, 1])
with col2:
    col_img, col_text = st.columns([0.2, 1])
    with col_img:
        st.image("logo/csusb_logo.png", width=60)
    with col_text:
        st.markdown("<h3 style='font-size: 22px; margin: 0px;'>CSUSB Study Podcast Assistant</h3>", unsafe_allow_html=True)

apik = os.environ["GROQ_API_KEY"] = "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"
if not apik:
    st.error("Error: Please set your GROQ_API_Key variable.")
    st.stop()

chat_alpha = init_chat_model("llama3-8b-8192", model_provider="groq")
chat_beta = init_chat_model("llama3-70b-8192", model_provider="groq")
messages = [SystemMessage(content="You are an AI assistant that will help.")]

if "podcast_started" not in st.session_state:
    st.session_state["podcast_started"] = False
if "conf_matrix" not in st.session_state:
    st.session_state.conf_matrix = np.array([[0, 0], [0, 0]])
if "last_upload_time" not in st.session_state:
    st.session_state["last_upload_time"] = None
if "show_podcast_warning" not in st.session_state:
    st.session_state.show_podcast_warning = False
if "show_test_warning" not in st.session_state:
    st.session_state.show_test_warning = False

def extract_text_from_pdf(pdf_file):
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        return "".join([page.extract_text() for page in pdf_reader.pages])
    except Exception as e:
        return f"Error extracting PDF text: {str(e)}"

user_ip = get_user_ip_ad()
if not is_csusb(user_ip):
    st.warning("Access denied")
    st.stop()
else:
    uploaded_file = st.file_uploader("Upload a PDF document (Max: 10MB)", type=["pdf"])

if uploaded_file:
    current_time = datetime.now()
    if (
        "last_upload_time" in st.session_state and
        st.session_state["last_upload_time"] is not None and
        current_time - st.session_state["last_upload_time"] < timedelta(minutes=2)
    ):
        wait_time = timedelta(minutes=2) - (current_time - st.session_state["last_upload_time"])
        st.warning(f"‚ö†Ô∏è Please wait {int(wait_time.total_seconds() // 60)} min {int(wait_time.total_seconds() % 60)} sec before uploading another file.")
        uploaded_file = None
    elif uploaded_file.size > 10 * 1024 * 1024:
        st.error("‚ùå File size exceeds the 10MB limit. Please upload a smaller PDF.")
        uploaded_file = None
    else:
        extracted_text = extract_text_from_pdf(uploaded_file)
        st.success("‚úÖ PDF uploaded successfully!")

col1, col2 = st.columns(2)
with col1:
    start_clicked = st.button(":material/voice_chat: Start AI Podcast", key="start_podcast_button_1")
with col2:
    test_clicked = st.button(":material/bug_report: Test AI", key="test_ai_button")

if start_clicked:
    st.session_state["show_test_warning"] = False
    if not uploaded_file:
        st.session_state["show_podcast_warning"] = True
    else:
        st.session_state["podcast_started"] = True
        st.session_state["last_upload_time"] = datetime.now()
        st.session_state["show_podcast_warning"] = False

if test_clicked:
    st.session_state["show_podcast_warning"] = False
    if not uploaded_file or not extracted_text:
        st.session_state["show_test_warning"] = True
    else:
        st.session_state["test_ai_clicked"] = True
        st.session_state["show_test_warning"] = False

if st.session_state["show_podcast_warning"]:
    st.warning("üö® Please upload a PDF before starting the podcast.")
elif st.session_state["show_test_warning"]:
    st.warning("üö® Please upload a PDF before testing the AI.")

def update_sidebar():
    with st.sidebar:
        st.markdown("### Confusion Matrix")
        st.write(pd.DataFrame(st.session_state.conf_matrix, 
                            columns=["Answered Correctly", "Not Answered"],
                            index=["Actual Yes", "Actual No"]))

        tp, fn = st.session_state.conf_matrix[0, 0], st.session_state.conf_matrix[1, 0]
        fp = st.session_state.conf_matrix[0, 1] if 0 in st.session_state.conf_matrix.shape else 0
        tn = st.session_state.conf_matrix[1, 1] if 1 in st.session_state.conf_matrix.shape else 0

        total = tp + tn + fp + fn
        model_accuracy = ((tp + tn) / total) * 100 if total > 0 else 0
        precision = (tp / (tp + fp)) * 100 if (tp + fp) > 0 else 0
        recall = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0
        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        specificity = (tn / (tn + fp)) * 100 if (tn + fp) > 0 else 0

        st.markdown("### Model Metrics")
        st.write(f"**Model Accuracy:** {model_accuracy:.2f}%")
        st.write(f"**Precision:** {precision:.2f}%")
        st.write(f"**Recall (Sensitivity):** {recall:.2f}%")
        st.write(f"**Specificity:** {specificity:.2f}%")
        st.write(f"**F1 Score:** {f1_score:.2f}%")

        if st.button("üîÑ Reset Metrics", key="reset_button"):
            st.session_state.conf_matrix = np.array([[0, 0], [0, 0]])
            st.session_state["podcast_started"] = False
            st.success("Confusion Matrix & Model Metrics Reset!")
            st.experimental_rerun()

def start_ai_podcast():
    st.markdown("## üéôÔ∏è Welcome to the AI Podcast")
    messages = []
    start_time = time.time()
    max_duration = 180

    from PyPDF2 import PdfReader
    try:
        reader = PdfReader(uploaded_file)
        chunks = [page.extract_text() or "" for page in reader.pages if page.extract_text()]
    except Exception as e:
        st.error(f"Failed to extract document chunks: {e}")
        return

    if not chunks:
        st.warning("No readable content found in the uploaded PDF.")
        return

    chunk_index = 0
    context = extracted_text[:4000]

    intro_prompt = f"""
    You're Alpha, kicking off a casual podcast with your co-host Beta.
    Say hi, drop your name, and mention you're diving into a doc together.
    Keep it under 2 sentences. Make it relaxed, friendly, not robotic.

    Document:
    {context}
    """
    intro = chat_alpha.invoke([HumanMessage(content=intro_prompt)]).content.strip()
    st.markdown(f"**Alpha:** {intro}")
    speak_text(intro, voice="alpha")

    st.markdown("---")
    q_num = 0
    last_beta_response = None

    while time.time() - start_time < max_duration:
        context = chunks[chunk_index][:4000]

        if last_beta_response:
            tone = random.choice(["curious", "amused", "sarcastic", "chill", "deep thinker"])
            alpha_prompt = f"""
            You're Alpha, a podcast host with a {tone} vibe.
            React to what Beta just said or ask a follow-up. Keep it smooth and natural.
            Avoid names and labels.
            Be very brief, three sentences max.

            Context:
            {context}

            Beta just said:
            {last_beta_response}
            """
        else:
            alpha_prompt = f"""
            You're Alpha, podcast host. Ask a quick, casual question based on the doc.
            Keep it real and tight, with short, quick, questions.

            Document:
            {context}
            """

        alpha_question = chat_alpha.invoke([HumanMessage(content=alpha_prompt)]).content.strip()
        st.markdown(f"**Alpha:** {alpha_question}")
        speak_text(alpha_question, voice="alpha")

        beta_prompt = f"""
        You're Beta, the podcast co-host. Answer Alpha's question based ONLY on the doc below.
        Keep it short, conversational. If unsure, say something casual like 'Not sure on that one.'

        Document:
        {context}

        Alpha asked:
        {alpha_question}
        """

        beta_response = chat_beta.invoke([SystemMessage(content=beta_prompt)]).content.strip()

        if beta_response.lower() in ["i don't know", "i do not know", "i'm not sure"]:
            beta_response = random.choice([
                "Hmm, I‚Äôm not totally sure about that.",
                "Yeah, that‚Äôs not really clear in the doc.",
                "Hard to say, honestly.",
                "Not sure on that one."
            ])

        st.markdown(f"**Beta:** {beta_response}")
        speak_text(beta_response, voice="beta")

        last_beta_response = beta_response
        chunk_index = (chunk_index + 1) % len(chunks)
        q_num += 1

    outro_prompt = """
    You're Alpha, the podcast host. Wrap up the episode in a friendly, casual way.
    Thank Beta and the audience, and sign off. Keep it short.
    """
    outro = chat_alpha.invoke([HumanMessage(content=outro_prompt)]).content.strip()
    st.markdown(f"**Alpha:** {outro}")
    speak_text(outro, voice="alpha")

# Function to test AI rephrasing and answering
def test_ai_rephrasing():
    if not uploaded_file or not extracted_text:
        st.warning("Please upload a PDF document before testing the AI.")
        return

    # 5 questions that CAN be answered based on the document
    answerable_questions = [
        "Summarize a key concept mentioned early in the document.",
        "What topic does the document mainly discuss?",
        "Name one specific detail or statistic mentioned in the document.",
        "What is one recommendation or conclusion from the document?",
        "Identify one author or source cited in the document."
    ]

    # 5 questions that are clearly unrelated and should not be answerable
    unanswerable_questions = [
        "What‚Äôs the capital of Iceland?",
        "Who won the Super Bowl in 2024?",
        "What‚Äôs the weather like in San Bernardino today?",
        "Who is the president of CSUSB?",
        "What‚Äôs the square root of 1,024?"
    ]

    all_questions = answerable_questions + unanswerable_questions
    random.shuffle(all_questions)

    for i, question in enumerate(all_questions):
        st.markdown(f"**Alpha:** {question}")
        speak_text(question, voice="alpha")

        if question in answerable_questions:
            beta_prompt = f"""
            You are Beta, a podcast co-host. Answer the question below using ONLY the uploaded document. If the document does not include an answer, say "I don't know."

            Document:
            {extracted_text[:4000]}

            Question: {question}
            """
        else:
            beta_prompt = f"""
            You are Beta, a podcast co-host. You can ONLY answer questions using the uploaded document. If the document does not provide the answer, say "I don't know."

            Document:
            {extracted_text[:4000]}

            Question: {question}
            """

        response = chat_beta.invoke([SystemMessage(content=beta_prompt)])
        ai_response = response.content.strip() if response else "I don't know"

        st.markdown(f"**Beta:** {ai_response}")
        speak_text(ai_response, voice="beta")

        # Update confusion matrix
        if "I don't know" in ai_response:
            st.session_state.conf_matrix[1, 1] += 1
        else:
            st.session_state.conf_matrix[0, 0] += 1

    update_sidebar()
      
# Create three buttons in separate columns above the text input box

# Chatbot Input for Document-based or Model-based Communication
col1, col2 = st.columns([4, 1])
with col1:
    user_input = st.text_input("Ask the Chatbot a Question (Document-based or Model-based)", key="chat_input")
with col2:
    st.markdown('<div class="submit-button-container">', unsafe_allow_html=True)
    
    if st.button(":material/send: Submit", key="submit_button_1"):
        if not uploaded_file:
            st.warning("‚ö†Ô∏è Please upload a PDF file before submitting your query.")
        else:
            if extracted_text:
                prompt = f"""
                You are an AI assistant. Based on the document provided below, respond to the user's query in 2‚Äì3 lines. 
                If the document does not contain the answer, respond with "I don't know." Do not guess or make up facts.

                --- Document Start ---
                {extracted_text[:10000]}
                --- Document End ---

                User Query: {user_input}
                """
            else:
                prompt = f"""
                You are an AI assistant with general knowledge. Respond to the user's query in 2‚Äì3 lines.
                If you don't know the answer, say "I don't know." Do not guess or make up facts.

                User Query: {user_input}
                """

            response = chat_alpha.invoke([SystemMessage(content=prompt)]) if uploaded_file else chat_beta.invoke([SystemMessage(content=prompt)])
            ai_response = response.content if response else "I do not know!"

            # Save the response into session_state so we can show it outside col2
            st.session_state.last_question = user_input
            st.session_state.last_answer = ai_response

            # Update confusion matrix
            if "I do not know!" in ai_response:
                st.session_state.conf_matrix[1, 0] += 1
            else:
                st.session_state.conf_matrix[0, 0] += 1

    st.markdown('</div>', unsafe_allow_html=True)


# üëá Show the response in the main body (not col2)
if "last_question" in st.session_state and "last_answer" in st.session_state:
    st.markdown("### Chatbot Response")
    st.markdown(f"**üßë User:** {st.session_state.last_question}")
    st.markdown(f"**ü§ñ AI:** {st.session_state.last_answer}")

# Unified Output Section (Ensuring Output Appears Below in a Single Row)
if st.session_state["podcast_started"]:
    st.write("---")  # Separator for clarity
    start_ai_podcast()  # Run the AI podcast function

if st.session_state.get("test_ai_clicked"):
    st.write("---")  # Separator for clarity
    test_ai_rephrasing()  # Run the AI rephrasing and answering function
